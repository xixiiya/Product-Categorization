{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (12,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "Mshs_may = pd.read_csv('MSHS Jan - May 2020 06192020.csv') #Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mshs_may = Mshs_may.loc[:, ~Mshs_may.columns.str.contains('^Unnamed')]\n",
    "Mshs_may.dropna(axis=0,how='all',inplace=True)\n",
    "Mshs_may=Mshs_may.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mshs_may['ItemDepartmentName'].nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Mshs_may['Item Description'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.tolist of 0            PAPER COPY WHITE TOP 10 CA\n",
       "1        CREAMER COFMATE LIQ ORIG 180CT\n",
       "2        COCOA MILK CHOCOLATE KCUP 24BX\n",
       "3                   POWDER BABY AEROSOL\n",
       "4         RENUZIT SUPER ODOR KILLER 7 5\n",
       "5             BINDER D RING 2 VUE WHITE\n",
       "6        REFILL FRSHMTIC AIR WICK LVNDR\n",
       "7              CLEANER SWIFFER WET 12BX\n",
       "8               MOP SWFR WETJET STARTER\n",
       "9        REFILL PDS SWIFFER WETJET 24CT\n",
       "10           PAPER COPY WHITE TOP 10 CA\n",
       "11       PAPER COPY RECYCLED 3HP 8 5X11\n",
       "12       CREAMER COFMATE LIQ ORIG 180CT\n",
       "13       COCOA MILK CHOCOLATE KCUP 24BX\n",
       "14                 GMCR TEA GREEN K CUP\n",
       "15       COFFEE KCUP FLGRS CLASSIC 24BX\n",
       "16                TONER HP MPS 508X YLW\n",
       "17                TONER HP MPS 508X MAG\n",
       "18               TONER HP MPS 508X CYAN\n",
       "19                TONER HP MPS 508X BLK\n",
       "20                CUTTER BOX 12PK WHITE\n",
       "21                CUTTER BOX 12PK WHITE\n",
       "22                CUTTER BOX 12PK WHITE\n",
       "23       WATER BTL NSTL PURE LIFE 24 CS\n",
       "24         SODA GINGER ALE 12OZ 24 CASE\n",
       "25           PEN G2 FINE 8PK ASST POUCH\n",
       "26       NOTES 3X3 POP UP DEEP CLR 12PK\n",
       "27         DUSTER OFFICE DEPOT 10oz 3PK\n",
       "28       NOTES POST IT LINED SS 4x4 6PK\n",
       "29        HOTCOCOA SWISSMISSW MRSH 50PK\n",
       "                      ...              \n",
       "49442    COFFEE K CUP DARK MAGIC 24 BOX\n",
       "49443          FORK PLASTIC 100CT WHITE\n",
       "49444     BAG STORAGE ZIPLOCK QT 500 BX\n",
       "49445      CUTLERY PLAS KNIFE 100CT WHT\n",
       "49446           HIGHLIGHTER 12PK YELLOW\n",
       "49447     PEN ROUND STIC BIC 60CT BLACK\n",
       "49448         SPOON PLASTIC 100CT WHITE\n",
       "49449        PAPER COPY WHITE TOP 10 CA\n",
       "49450       REFILL TIMEMIST CLEAN FRESH\n",
       "49451             TONER CANON 120 BLACK\n",
       "49452          STAMP XPL N10 141 5 X1 6\n",
       "49453            ORGANIZER DEEP DRWR BK\n",
       "49454    HOLDER NMBDG CONVERT CLIP 50CT\n",
       "49455       TONER HP 30A BLACK LASERJET\n",
       "49456     PAD PERF 5X8 LGL WHT RLD 12PK\n",
       "49457    PAD PERF 8 5X11 OD LGL RLD 12P\n",
       "49458      NOTEBOOK CAMB LIM 9 5X6 80CT\n",
       "49459     TAPE INVISIBLE 3 4X1000 10 PK\n",
       "49460       ORGNZR DSK 2 HORZ 6 UPRT ME\n",
       "49461           ORGANIZER MESH 5VERT BK\n",
       "49462             CUP PENCIL MESH BLACK\n",
       "49463     JUICE WELCHS APPLE 5 5OZ 48CA\n",
       "49464      SODA GINGER ALE 12OZ 24 CASE\n",
       "49465          COOKIE BISCOFF TWIN PACK\n",
       "49466         NV SWEET SALTY PEANUT BAR\n",
       "49467    GRANOLA BARS OATS N HONEY 18BX\n",
       "49468      FRESHENER LYSOL FRSH 10OZ EA\n",
       "49469          PAPER RECYCLED 92 BRT WE\n",
       "49470        TAPE STICKY BACK 5FT WHITE\n",
       "49471                               nan\n",
       "Name: Item Description, Length: 49472, dtype: object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "data= data.map(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "data.to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We use 183 stop-words from nltk library.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/xixikang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/xixikang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Import stopwords\n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.append(\"'s\")\n",
    "stopwords.append(\"'m\")\n",
    "stopwords.append(\"n't\")\n",
    "stopwords.append(\"br\")\n",
    "\n",
    "print (\"We use \" + str(len(stopwords)) + \" stop-words from nltk library.\")\n",
    "#print (stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization and stemming\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# REGULAR EXPRESSION\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def tokenization_and_stemming(text):\n",
    "    tokens = []\n",
    "    # exclude stop words and tokenize the document, generate a list of string \n",
    "    for word in nltk.word_tokenize(text):\n",
    "        if word.lower() not in stopwords:\n",
    "            tokens.append(word.lower())\n",
    "            #print(tokens)\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "            #print(filtered_tokens)\n",
    "            \n",
    "    # stemming\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['afterward', 'alon', 'alreadi', 'alway', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becom', 'besid', 'cri', 'describ', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'otherwis', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, there are 49472 reviews and 26392 terms.\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "tfidf_model = TfidfVectorizer(stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenization_and_stemming, ngram_range=(1,2))\n",
    "\n",
    "tfidf_matrix = tfidf_model.fit_transform(data) #fit the vectorizer to synopses\n",
    "\n",
    "print (\"In total, there are \" + str(tfidf_matrix.shape[0]) + \\\n",
    "      \" reviews and \" + str(tfidf_matrix.shape[1]) + \" terms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49472, 26392)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_selected_words = tfidf_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.        , ..., 0.06598838, 0.0550159 ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of  Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49472, 7811)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(data)\n",
    "bow_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "data1 = [] \n",
    "for i in sent_tokenize(str(data)): \n",
    "    temp = [] \n",
    "    # tokenize the sentence into words \n",
    "    for j in word_tokenize(i): \n",
    "        temp.append(j.lower()) \n",
    "  \n",
    "    data1.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
     ]
    }
   ],
   "source": [
    "#CBOW (Continuous Bag of Words)\n",
    "import gensim \n",
    "from gensim.models import Word2Vec \n",
    "#the model is loaded. It can be used to perform all of the tasks mentioned above.\n",
    "\n",
    "# getting word vectors of a word\n",
    "model1 = gensim.models.Word2Vec(data, min_count = 1,  \n",
    "                              size = 100, window = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
     ]
    }
   ],
   "source": [
    "#Skip Gram\n",
    "model2 = gensim.models.Word2Vec(data, min_count = 1, size = 100, \n",
    "                                             window = 5, sg = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity between words\n",
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "def cosine_sim_vectors(vec1,vec2):\n",
    "    vec1 = vec1.reshape(1,-1)\n",
    "    vec2 = vec2.reshape(1,-1)\n",
    "    return cosine_similarity(vec1,vec2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.62945776223706"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine Similarity between sentences\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "counterA = Counter(data[1])\n",
    "counterB = Counter(data[3])\n",
    "\n",
    "def counter_cosine_similarity(c1, c2):\n",
    "    terms = set(c1).union(c2)\n",
    "    dotprod = sum(c1.get(k, 0) * c2.get(k, 0) for k in terms)\n",
    "    magA = math.sqrt(sum(c1.get(k, 0)**2 for k in terms))\n",
    "    magB = math.sqrt(sum(c2.get(k, 0)**2 for k in terms))\n",
    "    return dotprod / (magA * magB)\n",
    "\n",
    "return counter_cosine_similarity(counterA,counterB)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49472,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = Mshs_may['ItemDepartmentName'].apply(str)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclssifier = SVC(kernel='linear')\n",
    "svclssifier.fit(X_train,y_train)\n",
    "\n",
    "y_pred = svclssifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   4,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    1,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,  655, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  976,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    4,    0],\n",
       "       [   0,    0,    0, ...,    0,    0, 1666]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)\n",
    "#classification_report(y_test,y_pred)\n",
    "#sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9755423797331896"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred1 = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    0,    1],\n",
       "       [   0,    0,    0, ...,    0,    0,    2],\n",
       "       [   0,    0,  658, ...,    0,    0,    1],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  977,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0, 1673]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred1)\n",
    "#classification_report(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9342406683735346"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# K Nearest Neighbors\n",
    "classifier_KNN = KNeighborsClassifier()\n",
    "\n",
    "# Random Forest\n",
    "classifier_RF = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9716345505996496"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_RF.fit(X_train, y_train)\n",
    "classifier_RF.predict(X_test)\n",
    "classifier_RF.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9574855140816602"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_KNN.fit(X_train, y_train)\n",
    "classifier_KNN.predict(X_test)\n",
    "classifier_KNN.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation---Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9233871  0.92891132 0.92562103 0.92991329 0.93180831]\n",
      "Model accuracy of Naive Bayes is 0.9279282099366647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97379032 0.97231435 0.97169266 0.97528902 0.98002027]\n",
      "Model accuracy of SVM is 0.9746213239853574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96990207 0.9666907  0.96952629 0.97239884 0.97408426]\n",
      "Model accuracy of Random Forest is 0.9705204329482389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95722926 0.95270368 0.95060659 0.95592486 0.95555234]\n",
      "Model accuracy of KNN is 0.9544033438322076\n"
     ]
    }
   ],
   "source": [
    "model_names = ['Naive Bayes','SVM','Random Forest','KNN']\n",
    "model_list = [clf, svclssifier,classifier_RF, classifier_KNN]\n",
    "count = 0\n",
    "\n",
    "for classifier in model_list:\n",
    "    cv_score = model_selection.cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "    print(cv_score)\n",
    "    print('Model accuracy of ' + model_names[count] + ' is ' + str(cv_score.mean()))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for Parameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# helper function for printing out grid search results \n",
    "def print_grid_search_metrics(gs):\n",
    "    print (\"Best score: \" + str(gs.best_score_))\n",
    "    print (\"Best parameters set:\")\n",
    "    best_parameters = gs.best_params_\n",
    "    for param_name in sorted(best_parameters.keys()):\n",
    "        print(param_name + ':' + str(best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-35-79901d62a44f>\", line 11, in <module>\n",
      "    Grid_RF.fit(X_train, y_train)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\", line 722, in fit\n",
      "    self._run_search(evaluate_candidates)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\", line 1191, in _run_search\n",
      "    evaluate_candidates(ParameterGrid(self.param_grid))\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\", line 711, in evaluate_candidates\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 920, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 528, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\", line 333, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 920, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\", line 119, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\", line 801, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\", line 366, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/anaconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/anaconda3/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/anaconda3/lib/python3.7/posixpath.py\", line 410, in _joinrealpath\n",
      "    if isabs(rest):\n",
      "  File \"/anaconda3/lib/python3.7/posixpath.py\", line 68, in isabs\n",
      "    return s.startswith(sep)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Possible hyperparamter options for Random Forest\n",
    "# Choose the number of trees\n",
    "parameters = {\n",
    "    'max_depth': [10, 20, 30, 40, None],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'n_estimators' : [20,40,60,80,100]\n",
    "}\n",
    "Grid_RF = GridSearchCV(RandomForestClassifier(),parameters, cv=5)\n",
    "Grid_RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_grid_search_metrics(Grid_RF)\n",
    "best_RF_model = Grid_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible hyperparamter options for SVM\n",
    "# Choose the number of trees\n",
    "parameters = {\n",
    "    'kernels ' : ('rbf', 'poly','linear'),\n",
    "    'gammas': (0.1, 1, 10, 100),\n",
    "    'C': (0.1, 1, 10, 100, 1000),\n",
    "    'degrees': (0, 1, 2, 3, 4, 5, 6)   \n",
    "}\n",
    "Grid_SVM = GridSearchCV(svclssifier(),parameters, cv=5)\n",
    "Grid_SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_grid_search_metrics(Grid_SVM)\n",
    "best_SVM_model = Grid_SVM.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible hyperparamter options for KNN\n",
    "parameters = {\n",
    "    'leaf_size ' : list(range(1,50)),\n",
    "    'n_neighbors':list(range(1,50)),\n",
    "    'p': [1,2]\n",
    "}\n",
    "Grid_KNN = GridSearchCV(classifier_KNN(),parameters, cv=5)\n",
    "Grid_KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_grid_search_metrics(Grid_KNN)\n",
    "best_KNN_model = Grid_KNN.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# calculate accuracy, precision and recall, [[tn, fp],[]]\n",
    "def cal_evaluation(classifier, cm):\n",
    "    tn = cm[0][0]\n",
    "    fp = cm[0][1]\n",
    "    fn = cm[1][0]\n",
    "    tp = cm[1][1]\n",
    "    accuracy  = (tp + tn) / (tp + fp + fn + tn + 0.0)\n",
    "    precision = tp / (tp + fp + 0.0)\n",
    "    recall = tp / (tp + fn + 0.0)\n",
    "    print (classifier)\n",
    "    print (\"Accuracy is: \" + str(accuracy))\n",
    "    print (\"precision is: \" + str(precision))\n",
    "    print (\"recall is: \" + str(recall))\n",
    "    print ()\n",
    "\n",
    "# print out confusion matrices\n",
    "def draw_confusion_matrices(confusion_matricies):\n",
    "    class_names = ['Not','Churn']\n",
    "    for cm in confusion_matrices:\n",
    "        classifier, cm = cm[0], cm[1]\n",
    "        cal_evaluation(classifier, cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix, accuracy, precison and recall for random forest and logistic regression\n",
    "confusion_matrices = [\n",
    "    (\"Random Forest\", confusion_matrix(y_test,best_RF_model.predict(X_test))),\n",
    "    (\"SVM\", confusion_matrix(y_test,best_SVM_model.predict(X_test))),\n",
    "    (\"K nearest neighbor\", confusion_matrix(y_test, best_KNN_model.predict(X_test)))\n",
    "]\n",
    "\n",
    "draw_confusion_matrices(confusion_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve and AUC score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# Use predict_proba to get the probability results of Random Forest\n",
    "y_pred_rf = best_RF_model.predict_proba(X_test)[:, 1]\n",
    "fpr_rf, tpr_rf, thresh = roc_curve(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_RF_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve of Random Forest result\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve - RF model')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# AUC score\n",
    "metrics.auc(fpr_rf,tpr_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# Use predict_proba to get the probability results of Random Forest\n",
    "y_pred_KNN = best_KNN_model.predict_proba(X_test)[:, 1]\n",
    "fpr_KNN, tpr_KNN, thresh = roc_curve(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_KNN_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve of Random Forest result\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_KNN, tpr_KNN, label='KNN')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve - KNN model')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# AUC score\n",
    "metrics.auc(fpr_KNN, tpr_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime.now() - begin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%f seconds\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
